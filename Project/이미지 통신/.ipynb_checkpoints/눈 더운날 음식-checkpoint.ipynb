{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 지식IN 을 통한 검색을 워드클라우드\n",
    "\n",
    "- 물론 네이버 개발자 API를 이용하면 훨씬 빠르게 데이타를 가져올 수 있다\n",
    "\n",
    "- 간단하게 주소창의 주소로 크롤링한다.\n",
    "\n",
    "- 크롬 개발자모드에서 검색부분을 가져온다 ( 각 dl 태그 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 간단한 한글 폰드 등록\n",
    "from matplotlib import rc\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "rc('font', family='Malgun Gothic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d8c5fb899b44e09590d5c10ead5a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1000 만개 정도의 검색 결과를 읽어온다.\n",
    "# 첫번째 페이지 start=1, 두번째 페이지인 경우 start=11인거 확인한다.\n",
    "# 웹 페이지 직접 접근 할 땐느 간단이 time.sleep()으로 요청을 간격적으로 한다.\n",
    "# 시간이 10분 정도 소요되기에 상태바를 보여준다. ( tqdm.tqdm_notebook 이용)\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "present_candi_text = []\n",
    "present_candi_text1 = []\n",
    "present_candi_text2 = []\n",
    "present_candi_text3 = []\n",
    "present_candi_text4 = []\n",
    "present_candi_text5 = []\n",
    "\n",
    "tmp1 = 'https://search.naver.com/search.naver?where=kin'\n",
    "html = tmp1 + '&sm=tab_jum&ie=utf8&query={key_word}&kin_start={num}'\n",
    "\n",
    "\n",
    "for n in tqdm_notebook(range(1,1000,10)):\n",
    "    response = urlopen(html.format(num=n, key_word=urllib.parse.quote('눈 더운 날 음식 한식')))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    tmp = soup.find_all('dl')\n",
    "    for line in tmp:\n",
    "        present_candi_text.append(line.text)\n",
    "    time.sleep(5)\n",
    "for n in tqdm_notebook(range(1,1000,10)):\n",
    "    response = urlopen(html.format(num=n, key_word=urllib.parse.quote('눈 더운 날 음식 중식')))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    tmp = soup.find_all('dl')\n",
    "    for line in tmp:\n",
    "        present_candi_text1.append(line.text)\n",
    "    time.sleep(5)\n",
    "for n in tqdm_notebook(range(1,1000,10)):\n",
    "    response = urlopen(html.format(num=n, key_word=urllib.parse.quote('눈 더운 날 음식 일식')))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    tmp = soup.find_all('dl')\n",
    "    for line in tmp:\n",
    "        present_candi_text2.append(line.text)\n",
    "    time.sleep(5)\n",
    "for n in tqdm_notebook(range(1,1000,10)):\n",
    "    response = urlopen(html.format(num=n, key_word=urllib.parse.quote('눈 더운 날 음식 양식')))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    tmp = soup.find_all('dl')\n",
    "    for line in tmp:\n",
    "        present_candi_text3.append(line.text)\n",
    "    time.sleep(5)\n",
    "for n in tqdm_notebook(range(1,1000,10)):\n",
    "    response = urlopen(html.format(num=n, key_word=urllib.parse.quote('눈 더운 날 음식 분식')))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    tmp = soup.find_all('dl')\n",
    "    for line in tmp:\n",
    "        present_candi_text4.append(line.text)\n",
    "    time.sleep(5)\n",
    "for n in tqdm_notebook(range(1,1000,10)):\n",
    "    response = urlopen(html.format(num=n, key_word=urllib.parse.quote('눈 더운 날 음식 동남아')))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    tmp = soup.find_all('dl')\n",
    "    for line in tmp:\n",
    "        present_candi_text5.append(line.text)\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(present_candi_text)\n",
    "len(present_candi_text1)\n",
    "len(present_candi_text2)\n",
    "len(present_candi_text3)\n",
    "len(present_candi_text4)\n",
    "len(present_candi_text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#만개의 글을 하나의 변수에 저장\n",
    "\n",
    "import nltk\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt= Okt()\n",
    "\n",
    "present_text =''\n",
    "present_text1 =''\n",
    "present_text2 =''\n",
    "present_text3 =''\n",
    "present_text4 =''\n",
    "present_text5 =''\n",
    "\n",
    "for each_line in present_candi_text[:10000]:\n",
    "    present_text = present_text + each_line + '\\n'\n",
    "for each_line in present_candi_text1[:10000]:\n",
    "    present_text1 = present_text1 + each_line + '\\n'\n",
    "for each_line in present_candi_text2[:10000]:\n",
    "    present_text2 = present_text2 + each_line + '\\n'\n",
    "for each_line in present_candi_text3[:10000]:\n",
    "    present_text3 = present_text3 + each_line + '\\n'\n",
    "for each_line in present_candi_text4[:10000]:\n",
    "    present_text4 = present_text4 + each_line + '\\n'\n",
    "for each_line in present_candi_text5[:10000]:\n",
    "    present_text5 = present_text5 + each_line + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석\n",
    "tokens_ko = okt.morphs(present_text)\n",
    "tokens_ko1 = okt.morphs(present_text1)\n",
    "tokens_ko2 = okt.morphs(present_text2)\n",
    "tokens_ko3 = okt.morphs(present_text3)\n",
    "tokens_ko4 = okt.morphs(present_text4)\n",
    "tokens_ko5 = okt.morphs(present_text5)\n",
    "tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = nltk.Text(tokens_ko,name='눈 더운 날 음식 한식')\n",
    "ko1 = nltk.Text(tokens_ko1,name='눈 더운 날 음식 중식')\n",
    "ko2 = nltk.Text(tokens_ko2,name='눈 더운 날 음식 일식')\n",
    "ko3 = nltk.Text(tokens_ko3,name='눈 더운 날 음식 양식')\n",
    "ko4 = nltk.Text(tokens_ko4,name='눈 더운 날 음식 분식')\n",
    "ko5 = nltk.Text(tokens_ko5,name='눈 더운 날 음식 동남아')\n",
    "print(len(ko.tokens))\n",
    "print(len(set(ko.tokens))) #중복제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko.vocab().most_common()\n",
    "ko1.vocab().most_common()\n",
    "ko2.vocab().most_common()\n",
    "ko3.vocab().most_common()\n",
    "ko4.vocab().most_common()\n",
    "ko5.vocab().most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의미없는 단어들을 수동으로 제거해준다.\n",
    "stop_words = ['.','가','요','답변','...','을','수','에','질문','제','를','이','도',\n",
    "                      '좋','1','는','로','으로','2','것','은','다',',','니다','대','들',\n",
    "                      '2017','들','데','..','의','때','겠','고','게','네요','한','일','할',\n",
    "                      '10','?','하는','06','주','려고','인데','거','좀','는데','~','ㅎㅎ',\n",
    "                      '하나','이상','20','뭐','까','있는','잘','습니다','다면','했','주려',\n",
    "                      '지','있','못','후','중','줄','6','과','어떤','기본','!!',\n",
    "                      '단어','선물해','라고','중요한','합','가요','....','보이','네','무지']\n",
    "\n",
    "tokens_ko = [each_word for each_word in tokens_ko \n",
    "                          if each_word not in stop_words]\n",
    "tokens_ko1 = [each_word for each_word in tokens_ko1 \n",
    "                          if each_word not in stop_words]\n",
    "tokens_ko2 = [each_word for each_word in tokens_ko2 \n",
    "                          if each_word not in stop_words]\n",
    "tokens_ko3 = [each_word for each_word in tokens_ko3 \n",
    "                          if each_word not in stop_words]\n",
    "tokens_ko4 = [each_word for each_word in tokens_ko4 \n",
    "                          if each_word not in stop_words]\n",
    "tokens_ko5 = [each_word for each_word in tokens_ko5 \n",
    "                          if each_word not in stop_words]\n",
    "\n",
    "ko = nltk.Text(tokens_ko,name='눈 더운 날 음식 한식')\n",
    "ko.vocab().most_common()\n",
    "\n",
    "ko1 = nltk.Text(tokens_ko1,name='눈 더운 날 음식 중식')\n",
    "ko1.vocab().most_common()\n",
    "\n",
    "ko2 = nltk.Text(tokens_ko2,name='눈 더운 날 음식 일식')\n",
    "ko2.vocab().most_common()\n",
    "\n",
    "ko3 = nltk.Text(tokens_ko3,name='눈 더운 날 음식 양식')\n",
    "ko3.vocab().most_common()\n",
    "\n",
    "ko4 = nltk.Text(tokens_ko4,name='눈 더운 날 음식 분식')\n",
    "ko4.vocab().most_common()\n",
    "\n",
    "ko5 = nltk.Text(tokens_ko5,name='눈 더운 날 음식 동남아')\n",
    "ko5.vocab().most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "ko.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 워드 크라우드 그리기 \"\"\"\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "data = ko.vocab().most_common(100)\n",
    "data1 = ko1.vocab().most_common(100)\n",
    "data2 = ko2.vocab().most_common(100)\n",
    "data3 = ko3.vocab().most_common(100)\n",
    "data4 = ko4.vocab().most_common(100)\n",
    "data5 = ko5.vocab().most_common(100)\n",
    "\n",
    "wordcloud = WordCloud(font_path = 'c:Windows/Fonts/malgun.ttf',relative_scaling=0.2, background_color ='white').generate_from_frequencies(dict(data))\n",
    "wordcloud1 = WordCloud(font_path = 'c:Windows/Fonts/malgun.ttf',relative_scaling=0.2, background_color ='white').generate_from_frequencies(dict(data1))\n",
    "wordcloud2 = WordCloud(font_path = 'c:Windows/Fonts/malgun.ttf',relative_scaling=0.2, background_color ='white').generate_from_frequencies(dict(data2))\n",
    "wordcloud3 = WordCloud(font_path = 'c:Windows/Fonts/malgun.ttf',relative_scaling=0.2, background_color ='white').generate_from_frequencies(dict(data3))\n",
    "wordcloud4 = WordCloud(font_path = 'c:Windows/Fonts/malgun.ttf',relative_scaling=0.2, background_color ='white').generate_from_frequencies(dict(data4))\n",
    "wordcloud5 = WordCloud(font_path = 'c:Windows/Fonts/malgun.ttf',relative_scaling=0.2, background_color ='white').generate_from_frequencies(dict(data5))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud1)\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud2)\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud3)\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud4)\n",
    "plt.axis('off')\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(wordcloud5)\n",
    "plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
